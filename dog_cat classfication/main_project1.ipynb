{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(9):\\n    plt.subplot(3,3,i+1)\\n    img = train_generator.next()\\n    print(img[1])\\n    plt.imshow(img[0][0])\\nplt.show()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "data_path = \"kaggle_dogcat/train\"\n",
    "test_path = \"kaggle_dogcat/test\"\n",
    "\n",
    "row_size = 300\n",
    "column_size = 300\n",
    "batch_size = 10\n",
    "# 建立image generator\n",
    "train_gene = keras.preprocessing.image.ImageDataGenerator(rotation_range=30,\n",
    "                                                            width_shift_range=0.1,\n",
    "                                                            height_shift_range=0.1,\n",
    "                                                            rescale=1/255,\n",
    "                                                            horizontal_flip=True)\n",
    "\n",
    "# 額外產生圖片\n",
    "train_generator = train_gene.flow_from_directory(data_path,\n",
    "                                                target_size=(row_size, column_size),\n",
    "                                                batch_size=batch_size)\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    img = train_generator.next()\n",
    "    print(img[1])\n",
    "    plt.imshow(img[0][0])\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新整理測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "# 整理測試資料\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"kaggle_dogcat/test/test\"\n",
    "\n",
    "x_test = []\n",
    "file_list = os.listdir(data_path)\n",
    "for data in file_list:\n",
    "    img = cv2.imread(os.path.join(data_path,data))\n",
    "    res = cv2.resize(img, dsize=(row_size, column_size), interpolation=cv2.INTER_CUBIC)\n",
    "    x_test.append(res/255)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0908 00:16:56.018635  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0908 00:16:56.030602  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0908 00:16:56.032598  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0908 00:16:56.050549  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0908 00:16:56.052544  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0908 00:16:56.980691  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0908 00:16:57.030558  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0908 00:16:57.253289  6988 deprecation_wrapper.py:119] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0908 00:16:57.331081  6988 deprecation.py:323] From c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 286, 286, 10)      6760      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 286, 286, 10)      40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 143, 143, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 134, 134, 20)      20020     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 134, 134, 20)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 67, 67, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 63, 63, 30)        15030     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 63, 63, 30)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 29, 29, 40)        10840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 29, 29, 40)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 40)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7840)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               784100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 837,352\n",
      "Trainable params: 837,152\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.7229 - acc: 0.6000\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.6200 - acc: 0.6537\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.5957 - acc: 0.6879\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.5573 - acc: 0.7146\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.5360 - acc: 0.7398\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.5162 - acc: 0.7470\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.4979 - acc: 0.7597\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.4767 - acc: 0.7677\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.4544 - acc: 0.7883\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.4394 - acc: 0.7950\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.4238 - acc: 0.8072\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 169s 169ms/step - loss: 0.4119 - acc: 0.8102\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 173s 173ms/step - loss: 0.3915 - acc: 0.8215\n",
      "Epoch 14/25\n",
      "1000/1000 [==============================] - 167s 167ms/step - loss: 0.3733 - acc: 0.8360\n",
      "Epoch 15/25\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.3771 - acc: 0.8312\n",
      "Epoch 16/25\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.3632 - acc: 0.8375\n",
      "Epoch 17/25\n",
      "1000/1000 [==============================] - 169s 169ms/step - loss: 0.3583 - acc: 0.8425\n",
      "Epoch 18/25\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3385 - acc: 0.8517s - loss: 0.3382 - a\n",
      "Epoch 19/25\n",
      "1000/1000 [==============================] - 175s 175ms/step - loss: 0.3307 - acc: 0.8546\n",
      "Epoch 20/25\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.3343 - acc: 0.8503\n",
      "Epoch 21/25\n",
      "1000/1000 [==============================] - 161s 161ms/step - loss: 0.3301 - acc: 0.8538\n",
      "Epoch 22/25\n",
      "1000/1000 [==============================] - 160s 160ms/step - loss: 0.3155 - acc: 0.8653\n",
      "Epoch 23/25\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.3131 - acc: 0.8653\n",
      "Epoch 24/25\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.3144 - acc: 0.8640\n",
      "Epoch 25/25\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.3090 - acc: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b2cd829b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cnn_model():\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    layer_list = [keras.layers.Conv2D(filters=10,kernel_size=(15,15),\n",
    "                                      input_shape=(row_size,column_size,3),\n",
    "                                      activation='relu'),\n",
    "                  keras.layers.BatchNormalization(),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Conv2D(filters=20,kernel_size=(10,10),activation='relu'),\n",
    "                  keras.layers.BatchNormalization(),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Conv2D(filters=30,kernel_size=(5,5),activation='relu'),\n",
    "                  keras.layers.BatchNormalization(),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Conv2D(filters=40,kernel_size=(3,3),activation='relu'),\n",
    "                  keras.layers.BatchNormalization(),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Flatten(),\n",
    "                  keras.layers.Dense(units=100,activation='relu'),\n",
    "                  keras.layers.Dense(units=2,activation='softmax')]\n",
    "    \n",
    "    model = keras.models.Sequential(layer_list)\n",
    "    return model\n",
    "\n",
    "cnn_model = cnn_model()\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "cnn_model.fit_generator(train_generator,\n",
    "                        epochs=25,\n",
    "                        steps_per_epoch=1000,\n",
    "                       shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>0.087256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>0.723323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002</td>\n",
       "      <td>0.999726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003</td>\n",
       "      <td>0.012620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004</td>\n",
       "      <td>0.829181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>005</td>\n",
       "      <td>0.961019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>006</td>\n",
       "      <td>0.148309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007</td>\n",
       "      <td>0.978520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>008</td>\n",
       "      <td>0.993866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>009</td>\n",
       "      <td>0.998451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>010</td>\n",
       "      <td>0.080151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>011</td>\n",
       "      <td>0.996754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>012</td>\n",
       "      <td>0.049361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>013</td>\n",
       "      <td>0.751541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>014</td>\n",
       "      <td>0.808613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>015</td>\n",
       "      <td>0.132282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>016</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>017</td>\n",
       "      <td>0.996071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>018</td>\n",
       "      <td>0.282907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>019</td>\n",
       "      <td>0.984404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Predicted\n",
       "0   000   0.087256\n",
       "1   001   0.723323\n",
       "2   002   0.999726\n",
       "3   003   0.012620\n",
       "4   004   0.829181\n",
       "5   005   0.961019\n",
       "6   006   0.148309\n",
       "7   007   0.978520\n",
       "8   008   0.993866\n",
       "9   009   0.998451\n",
       "10  010   0.080151\n",
       "11  011   0.996754\n",
       "12  012   0.049361\n",
       "13  013   0.751541\n",
       "14  014   0.808613\n",
       "15  015   0.132282\n",
       "16  016   0.007077\n",
       "17  017   0.996071\n",
       "18  018   0.282907\n",
       "19  019   0.984404"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred = cnn_model.predict(np.array(x_test))[:,1]\n",
    "output_df = pd.DataFrame([str(i).zfill(3) for i in range(len(pred))])\n",
    "output_df.columns = ['ID']\n",
    "output_df['Predicted'] = pred\n",
    "output_df.to_csv('res.csv',index=False)\n",
    "output_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
