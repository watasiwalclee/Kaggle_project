{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入及整理資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\lclee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "data_path = \"kaggle_dogcat/train\"\n",
    "class_list = os.listdir(data_path)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "row_size = 300\n",
    "column_size = 300\n",
    "image_gen = image.ImageDataGenerator(rotation_range=30,\n",
    "                                     width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    rescale=1/255)\n",
    "image_batch_size = 10\n",
    "'''\n",
    "# 整理訓練用資料\n",
    "for n in ['cats','dogs']:\n",
    "    class_path = os.path.join(data_path,n)\n",
    "    file_list = os.listdir(class_path)\n",
    "    for data in file_list:\n",
    "        img = cv2.imread(os.path.join(class_path,data))\n",
    "        \n",
    "        # 標籤\n",
    "        if n == 'cats':\n",
    "            train_label = [1]\n",
    "        elif n == 'dogs':\n",
    "            train_label = [0]\n",
    "        \n",
    "        #x_train.append(img)\n",
    "        #y_train.append(train_label)\n",
    "        \n",
    "        # 使用imageGenerator產製圖片\n",
    "        gen_img = image_gen.flow(np.array([img]),train_label,\n",
    "                                 batch_size=image_batch_size)\n",
    "        for i in range(image_batch_size):\n",
    "            gen_img_data = gen_img.next()\n",
    "            x_train.append(gen_img_data[0][0])\n",
    "            y_train.append(train_label)\n",
    "            \n",
    "x_test = []\n",
    "# 整理測試資料\n",
    "data_path = \"kaggle_dogcat/test\"\n",
    "file_list = os.listdir(data_path)\n",
    "for data in file_list:\n",
    "    img = cv2.imread(os.path.join(data_path,data))\n",
    "    x_test.append(img)\n",
    "\n",
    "# 順序打散\n",
    "index_list = list(range(len(x_train)))\n",
    "np.random.shuffle(index_list)    \n",
    "\n",
    "x_train = np.array(x_train)[index_list]\n",
    "y_train = np.array(y_train)[index_list]\n",
    "x_test = np.array(x_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 圖像預處理\n",
    "圖像的尺寸都不是固定的，但是CNN的input必須要固定下來\n",
    "所以必須先將圖片的格式統一\n",
    "作法為找出資料中圍度最大值，並將其補遺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# 將資料維度補齊\n",
    "resize_x_train = []\n",
    "resize_x_test = []\n",
    "# 訓練資料圖片重整\n",
    "for img in x_train:\n",
    "    res = cv2.resize(img, dsize=(row_size, column_size), interpolation=cv2.INTER_CUBIC)\n",
    "    resize_x_train.append(res)\n",
    "\n",
    "# 測試資料圖片重整\n",
    "for img in x_test:\n",
    "    res = cv2.resize(img, dsize=(row_size, column_size), interpolation=cv2.INTER_CUBIC)\n",
    "    resize_x_test.append(res)\n",
    "\n",
    "del x_train,x_test\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "# 記憶體不夠用，所以使用批次訓練的方式\n",
    "def data_generator(data_x,data_y,batch_size):\n",
    "    while True:\n",
    "        for d in range(0,len(data_x),batch_size):\n",
    "            x_train = np.array(data_x[d:int(d+batch_size)])\n",
    "            y_train = np.array(data_y[d:int(d+batch_size)])\n",
    "            yield x_train,y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型\n",
    "keras.layers.BatchNormalization(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "def cnn_model():\n",
    "    layer_list = [keras.layers.Conv2D(filters=5,kernel_size=(10,10),\n",
    "                                      input_shape=(row_size,column_size,3),\n",
    "                                      activation='relu'),\n",
    "                  keras.layers.BatchNormalization(),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Conv2D(filters=10,kernel_size=(5,5),activation='relu'),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Conv2D(filters=15,kernel_size=(3,3),activation='relu'),\n",
    "                  keras.layers.MaxPooling2D((2,2)),\n",
    "                  keras.layers.Flatten(),\n",
    "                  keras.layers.Dense(units=150,activation='relu'),\n",
    "                  keras.layers.Dense(units=2,activation='softmax')]\n",
    "    \n",
    "    model = keras.models.Sequential(layer_list)\n",
    "    return model\n",
    "\n",
    "cnn_model = cnn_model()\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "batch_size = 10\n",
    "trainning_generator = data_generator(resize_x_train,y_train,batch_size)\n",
    "\n",
    "cnn_model.fit_generator(trainning_generator,\n",
    "                        epochs=20,\n",
    "                        steps_per_epoch=int(len(resize_x_train)/batch_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred = cnn_model.predict(np.array(resize_x_test))[:,1]\n",
    "output_df = pd.DataFrame([str(i).zfill(3) for i in range(len(pred))])\n",
    "output_df.columns = ['ID']\n",
    "output_df['Predicted'] = pred\n",
    "output_df.to_csv('res.csv',index=False)\n",
    "output_df.head(20)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
